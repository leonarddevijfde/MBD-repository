{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA Workbench imports\n",
    "import ema_workbench\n",
    "from ema_workbench import (\n",
    "    Model, RealParameter, ScalarOutcome, MultiprocessingEvaluator,\n",
    "    ema_logging, Constant, Scenario, HypervolumeMetric,\n",
    "    GenerationalDistanceMetric, EpsilonIndicatorMetric,\n",
    "    InvertedGenerationalDistanceMetric, SpacingMetric, Constraint)\n",
    "from ema_workbench.em_framework.optimization import (\n",
    "    EpsilonProgress, to_problem, ArchiveLogger, epsilon_nondominated)\n",
    "from ema_workbench.analysis import parcoords\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_optimization_outputs(result, convergence, scenario_name, seed, output_dir=\"./archives\"):\n",
    "    \"\"\"\n",
    "    Save the optimization result and convergence data to CSV files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    result_path = os.path.join(output_dir, f\"result__scen{scenario_name}__seed{seed}.csv\")\n",
    "    convergence_path = os.path.join(output_dir, f\"convergence__scen{scenario_name}__seed{seed}.csv\")\n",
    "\n",
    "    result.to_csv(result_path, index=False)\n",
    "    pd.DataFrame(convergence).to_csv(convergence_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_optimization(evaluator, model, scenario, seed, epsilon, nfe):\n",
    "    \"\"\"\n",
    "    Run a single optimization instance for a given scenario and seed.\n",
    "    \"\"\"\n",
    "    convergence_metrics = [        \n",
    "                    ArchiveLogger(\n",
    "                        \"./archives\",\n",
    "                        [l.name for l in model.levers],\n",
    "                        [o.name for o in model.outcomes],\n",
    "                        base_filename=\"optimization.tar.gz\",\n",
    "                    ),\n",
    "                    EpsilonProgress(),\n",
    "                ]\n",
    "\n",
    "    result, convergence = evaluator.optimize(\n",
    "        nfe=nfe,\n",
    "        searchover=\"levers\",\n",
    "        epsilons=epsilon,\n",
    "        constraints=None,\n",
    "        convergence=convergence_metrics,\n",
    "        reference=scenario,\n",
    "    )\n",
    "\n",
    "    return result, convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(epsilon, nfe, scenarios, model):\n",
    "    \"\"\"\n",
    "    Run optimization using the EMA Workbench.\n",
    "\n",
    "    Parameters:\n",
    "    epsilon (list): The epsilon values for the optimization.\n",
    "    nfe (int): The number of function evaluations.\n",
    "    scenarios (list): List of scenarios to be evaluated.\n",
    "    model: The model to be used for optimization.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing results and convergences.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store results and convergence metrics\n",
    "    results = []\n",
    "    convergences = []\n",
    "\n",
    "    # Use MultiprocessingEvaluator for parallel processing\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        # Iterate over each scenario\n",
    "        for scenario in scenarios:\n",
    "            # Perform optimization three times for each scenario\n",
    "            for i in range(3):\n",
    "                # Define convergence metrics\n",
    "                convergence_metrics = [\n",
    "                    ArchiveLogger(\n",
    "                        \"./archives\",\n",
    "                        [l.name for l in model.levers],\n",
    "                        [o.name for o in model.outcomes],\n",
    "                        base_filename=\"optimization.tar.gz\",\n",
    "                    ),\n",
    "                    EpsilonProgress(),\n",
    "                ]\n",
    "\n",
    "                # Run the optimization\n",
    "                result, convergence = evaluator.optimize(\n",
    "                    nfe=nfe,\n",
    "                    searchover=\"levers\",\n",
    "                    epsilons=epsilon,\n",
    "                    constraints=None,\n",
    "                    convergence=convergence_metrics,\n",
    "                    reference=scenario,\n",
    "                )\n",
    "\n",
    "                # Create result directory if it does not exist\n",
    "                result_dir = \"./archives\"\n",
    "                os.makedirs(result_dir, exist_ok=True)\n",
    "                \n",
    "                # Save the results and convergence metrics to CSV files\n",
    "                result.to_csv(os.path.join(result_dir, f\"result__scen{scenario.name}__seed{i}.csv\"))\n",
    "                pd.DataFrame(convergence).to_csv(os.path.join(result_dir, f\"convergence__scen{scenario.name}__seed{i}.csv\"))\n",
    "\n",
    "                # Append the results and convergence metrics to the lists\n",
    "                results.append(result)\n",
    "                convergences.append(convergence)\n",
    "    \n",
    "    # Return the results and convergence metrics\n",
    "    return results, convergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_optimization_results(path):\n",
    "    \"\"\"\n",
    "    Collect and combine all optimization result CSVs from a given folder.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): Path to the folder containing result CSV files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A single DataFrame with all the loaded results.\n",
    "    \"\"\"\n",
    "    result_frames = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".csv\") and filename.startswith(\"result__\"):\n",
    "            full_path = os.path.join(path, filename)\n",
    "            data = pd.read_csv(full_path)\n",
    "            result_frames.append(data)\n",
    "\n",
    "    if not result_frames:\n",
    "        raise ValueError(f\"No result files found in {path}\")\n",
    "\n",
    "    return pd.concat(result_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 8 workers\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'c:\\\\Users\\\\ralph\\\\Documents\\\\github mbd\\\\MBD-repository\\\\archives\\\\tmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 72\u001b[0m\n\u001b[0;32m     68\u001b[0m function_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilon_sets:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Run the optimization procedure\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     results, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Aggregate all results for analysis\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     combined_results \u001b[38;5;241m=\u001b[39m gather_optimization_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchives\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 26\u001b[0m, in \u001b[0;36mrun_optimization\u001b[1;34m(epsilon, nfe, scenarios, model)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m scenarios:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Perform optimization three times for each scenario\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Define convergence metrics\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         convergence_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 26\u001b[0m             \u001b[43mArchiveLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./archives\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevers\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcomes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimization.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     32\u001b[0m             EpsilonProgress(),\n\u001b[0;32m     33\u001b[0m         ]\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         result, convergence \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m     37\u001b[0m             nfe\u001b[38;5;241m=\u001b[39mnfe,\n\u001b[0;32m     38\u001b[0m             searchover\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m             reference\u001b[38;5;241m=\u001b[39mscenario,\n\u001b[0;32m     43\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ema_workbench\\em_framework\\optimization.py:684\u001b[0m, in \u001b[0;36mArchiveLogger.__init__\u001b[1;34m(self, directory, decision_varnames, outcome_varnames, base_filename)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(directory)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 684\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;241m=\u001b[39m base_filename\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_varnames \u001b[38;5;241m=\u001b[39m decision_varnames\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'c:\\\\Users\\\\ralph\\\\Documents\\\\github mbd\\\\MBD-repository\\\\archives\\\\tmp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ensure the archive directory exists\n",
    "os.makedirs(\"archives\", exist_ok=True)\n",
    "\n",
    "# Ensure the 'tmp' subdirectory does not conflict\n",
    "tmp_path = os.path.join(\"archives\", \"tmp\")\n",
    "if os.path.exists(tmp_path):\n",
    "    if os.path.isfile(tmp_path):\n",
    "        # If 'tmp' exists as a file, remove it\n",
    "        os.remove(tmp_path)\n",
    "    elif os.path.isdir(tmp_path):\n",
    "        # If 'tmp' exists as a directory, clear its contents\n",
    "        shutil.rmtree(tmp_path)\n",
    "# Create the 'tmp' directory\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "def load_scenarios_from_csv(filepath):\n",
    "    \"\"\"\n",
    "    Load and convert a scenario CSV file into a list of EMA Workbench Scenario objects.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    scenario_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        scenario_data = {\n",
    "            col: row[col]\n",
    "            for col in df.columns\n",
    "            if col.lower() != \"run id\" and col.lower() != \"run_id\"\n",
    "        }\n",
    "        scenario_name = row[\"Run ID\"] if \"Run ID\" in df.columns else row[\"run_id\"]\n",
    "        scenario_obj = Scenario(scenario_name, **scenario_data)\n",
    "        scenario_list.append(scenario_obj)\n",
    "\n",
    "    return scenario_list\n",
    "\n",
    "def plot_parallel_coordinates(results_df, epsilons, output_path):\n",
    "    \"\"\"\n",
    "    Plot a parallel coordinates graph from selected outcome columns in the results.\n",
    "    \"\"\"\n",
    "    selected_outcomes = [\n",
    "        'Expected Annual Damage', 'Dike Investment Costs', 'RfR Investment Costs',\n",
    "        'Evacuation Costs', 'Expected Number of Deaths', 'Total Investment Costs'\n",
    "    ]\n",
    "\n",
    "    subset = results_df[selected_outcomes]\n",
    "    limits = parcoords.get_limits(subset)\n",
    "    axes = parcoords.ParallelAxes(limits)\n",
    "    axes.plot(subset)\n",
    "\n",
    "    plt.title(f'Parallel Coordinates Plot for Epsilon {epsilons}')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable logging at INFO level\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    # Load the model setup for a specific problem formulation\n",
    "    model, _ = get_model_for_problem_formulation(0)\n",
    "\n",
    "    # Load scenario definitions\n",
    "    scenario_file = \"./data/selected_scenarios_outcomes.csv\"\n",
    "    scenario_list = load_scenarios_from_csv(scenario_file)\n",
    "\n",
    "    # Optimization parameters\n",
    "    epsilon_sets = [[1e6, 1e6, 1e6, 1e6, 10, 1e6]]\n",
    "    function_evals = 10000\n",
    "\n",
    "    for eps in epsilon_sets:\n",
    "        # Run the optimization procedure\n",
    "        results, _ = run_optimization(eps, function_evals, scenario_list, model)\n",
    "\n",
    "        # Aggregate all results for analysis\n",
    "        combined_results = gather_optimization_results(\"archives\")\n",
    "\n",
    "        # Generate and save the parallel coordinates plot\n",
    "        plot_parallel_coordinates(combined_results, eps, f\"parallel_coordinates_eps_{eps}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_parallel_coordinates(\u001b[43mresults\u001b[49m, epsilon_values)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "plot_parallel_coordinates(results, epsilon_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_policy(results):\n",
    "    # Initialize a list to store the indices of non-dominated policies\n",
    "    non_dominated_indices = []\n",
    "    # Loop over all pairs of policies\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results)):\n",
    "            # Skip if it's the same policy\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            # Check if policy i is dominated by policy j\n",
    "            if all(results.iloc[j] <= results.iloc[i]) and any(results.iloc[j] < results.iloc[i]):\n",
    "                break\n",
    "        else:\n",
    "            # If we didn't break from the loop, policy i is not dominated by any other policy\n",
    "            non_dominated_indices.append(i)\n",
    "\n",
    "    # Return only the non-dominated policies\n",
    "    return results.iloc[non_dominated_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
