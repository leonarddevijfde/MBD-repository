{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging,\n",
    "                           HypervolumeMetric, EpsilonIndicatorMetric, Scenario)\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fbb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model, steps = get_model_for_problem_formulation(2)\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    results = evaluator.optimize(nfe=5000, epsilons=[100,100,100,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661fb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scenarios(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    scenarios = []\n",
    "    for _, row in df.iterrows():\n",
    "        name = row['scenario']\n",
    "        parameters = row.drop(labels='scenario').to_dict()\n",
    "        scenarios.append(Scenario(name, **parameters))\n",
    "\n",
    "    return scenarios \n",
    "scenarios = load_scenarios('./data/Selected_Scenarios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1dfa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_epsilons(model, scenarios=None, nfe=10000, convergence_threshold=0.05,\n",
    "                          n_replicates=3, epsilons_range=None, convergence_interval=1000):\n",
    "    \"\"\"\n",
    "    Perform epsilon sensitivity analysis with scenario support.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : EMA Model\n",
    "        The model to optimize\n",
    "    scenarios : list or None\n",
    "        List of scenarios to evaluate against (if None, uses default optimization)\n",
    "    nfe : int\n",
    "        Number of function evaluations per optimization run\n",
    "    convergence_threshold : float\n",
    "        Threshold for epsilon progress convergence\n",
    "    n_replicates : int\n",
    "        Number of replicates for each epsilon configuration\n",
    "    epsilons_range : dict or None\n",
    "        Dictionary with outcome names as keys and epsilon ranges as values\n",
    "    convergence_interval : int\n",
    "        Interval for checking convergence\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing results organized by scenario\n",
    "    \"\"\"\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    # Handle default scenario case\n",
    "    if scenarios is None:\n",
    "        scenarios = [None]\n",
    "\n",
    "    # Initialize results structure\n",
    "    results = {\n",
    "        'scenarios': [],\n",
    "        'epsilons_tested': [],\n",
    "        'convergence_data': [],\n",
    "        'hypervolume': [],\n",
    "        'pareto_sets': []\n",
    "    }\n",
    "\n",
    "    # Determine epsilon ranges if not provided\n",
    "    if epsilons_range is None:\n",
    "        with MultiprocessingEvaluator(model) as evaluator:\n",
    "            results = evaluator.perform_experiments(1000)\n",
    "        _, outcomes = results\n",
    "        epsilons_range = {}\n",
    "        for outcome_name, values in outcomes.items():\n",
    "            outcome_range = np.percentile(\n",
    "                values, 95) - np.percentile(values, 5)\n",
    "            epsilons_range[outcome_name] = np.linspace(0.01 * outcome_range,\n",
    "                                                       0.1 * outcome_range, 5)\n",
    "\n",
    "    # Generate all epsilon combinations to test\n",
    "    epsilon_combinations = list(product(*epsilons_range.values()))\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        scenario_results = {\n",
    "            'epsilons_tested': [],\n",
    "            'convergence_data': [],\n",
    "            'hypervolume': [],\n",
    "            'pareto_sets': []\n",
    "        }\n",
    "\n",
    "        for epsilons in epsilon_combinations:\n",
    "            current_epsilons = dict(zip(epsilons_range.keys(), epsilons))\n",
    "\n",
    "            rep_convergence = []\n",
    "            rep_hypervolume = []\n",
    "            rep_pareto = []\n",
    "\n",
    "            for rep in range(n_replicates):\n",
    "                with MultiprocessingEvaluator(model) as evaluator:\n",
    "                    convergence = [EpsilonProgress()]\n",
    "                    hypervolume = [HypervolumeMetric(model.outcomes, scenario)]\n",
    "\n",
    "                    result = evaluator.optimize(\n",
    "                        nfe=nfe,\n",
    "                        epsilons=current_epsilons,\n",
    "                        convergence=convergence + hypervolume,\n",
    "                        convergence_threshold=convergence_threshold,\n",
    "                        convergence_interval=convergence_interval,\n",
    "                        reference=scenario\n",
    "                    )\n",
    "\n",
    "                    rep_convergence.append(convergence[0].epsilon_progress)\n",
    "                    rep_hypervolume.append(hypervolume[0].hypervolume[-1])\n",
    "                    rep_pareto.append(result)\n",
    "\n",
    "            scenario_results['epsilons_tested'].append(current_epsilons)\n",
    "            scenario_results['convergence_data'].append(\n",
    "                np.mean(rep_convergence, axis=0))\n",
    "            scenario_results['hypervolume'].append(np.mean(rep_hypervolume))\n",
    "            scenario_results['pareto_sets'].append(rep_pareto)\n",
    "\n",
    "        # Store scenario results\n",
    "        results['scenarios'].append(scenario)\n",
    "        results['epsilons_tested'].append(scenario_results['epsilons_tested'])\n",
    "        results['convergence_data'].append(\n",
    "            scenario_results['convergence_data'])\n",
    "        results['hypervolume'].append(scenario_results['hypervolume'])\n",
    "        results['pareto_sets'].append(scenario_results['pareto_sets'])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 24 workers\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "  0%|                                                 | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Load  model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "# Run epsilon sensitivity analysis\n",
    "results = find_optimal_epsilons(dike_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
